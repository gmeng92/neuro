{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/catalyst-team/neuro/blob/master/examples/Neuro_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZOKa-kgP_L-"
   },
   "source": [
    "# Neuro UNet/Meshnet Tutorial\n",
    "\n",
    "This is a reimplementation of [An (almost) instant brain atlas segmentation for\n",
    "large-scale studies](https://arxiv.org/pdf/1711.00457.pdf) using the publicly available Mindboggle Dataset.  Given only 70 volumes for training (typically 700+) and very minimal augmentations we can achieve a 0.6688 Mean Dice Score for a brain with a majority vote classification.  With more brains and normalizing the T1 scans we could likely perform better\n",
    "\n",
    "\n",
    "Authors: [Kevin Wang](https://github.com/ssktotoro/), [Alex Fedorov](https://github.com/Entodi/), [Sergey Kolesnikov](https://github.com/Scitator)\n",
    "\n",
    "[![Catalyst logo](https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/pics/catalyst_logo.png)](https://github.com/catalyst-team/catalyst)\n",
    "\n",
    "### Colab setup\n",
    "\n",
    "First of all, do not forget to change the runtime type to GPU. <br/>\n",
    "To do so click `Runtime` -> `Change runtime type` -> Select `\\\"Python 3\\\"` and `\\\"GPU\\\"` -> click `Save`. <br/>\n",
    "After that you can click `Runtime` -> `Run all` and watch the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8hXadxdP_L-"
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Download and install the latest versions of catalyst and other libraries required for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-T0L6CqRQ-23"
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "git clone https://github.com/catalyst-team/neuro.git\n",
    "pip install -r neuro/requirements/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k1BnwldEP_L-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch                                                                                                                                                                                              \n",
    "from tqdm import tqdm                                                                                                                                                                                     \n",
    "import numpy as np                                                                                                                                                                                        \n",
    "import nibabel as nib                                                                                                                                                                \n",
    "import collections                                                                                                                                                                                    \n",
    "from collections import OrderedDict \n",
    "collections.MutableMapping = collections.abc.MutableMapping                                                                                                                                                                                                                                                                                           \n",
    "import catalyst                                                                                                                                                                                           \n",
    "import pandas as pd  \n",
    "import os                                                                                                                                                                                                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.12.1, catalyst: 21.03.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catalyst.contrib.utils.pandas import dataframe_to_list                                                                                                                                               \n",
    "from torch.utils.data import SequentialSampler                                                                                                                                                            \n",
    "from torch.utils.data import DataLoader                                                                                                                                                                   \n",
    "from catalyst.data import ReaderCompose                                                                                                                                                                   \n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR                                                                                                                                        \n",
    "from catalyst.callbacks import CheckpointCallback                                                                                                                                                         \n",
    "from torch.nn import functional as F                                                                                                                                                                      \n",
    "from typing import List\n",
    "from catalyst import utils                                                                                                                                                                                   \n",
    "                                                                                                                                                                                                                                                                                                                                                                                    \n",
    "from catalyst import metrics                                                                                                                                                                              \n",
    "from catalyst.data import BatchPrefetchLoaderWrapper                                                                                                                                                      \n",
    "from catalyst.dl import Runner, LRFinder                                                                                                                                                                  \n",
    "                                                                                                                                                                                                          \n",
    "from catalyst.metrics.functional._segmentation import dice\n",
    "\n",
    "\n",
    "print(f\"torch: {torch.__version__}, catalyst: {catalyst.__version__}\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # \"\" - CPU, \"0\" - 1 GPU, \"0,1\" - MultiGPU\n",
    "\n",
    "SEED = 42\n",
    "utils.set_global_seed(SEED)\n",
    "utils.prepare_cudnn(deterministic=True)\n",
    "\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOGktFaFP_L_"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "We'll be using the Mindboggle 101 dataset for a multiclass 3d segmentation task.\n",
    "The dataset can be downloaded off osf with the following command from osfclient after you register with osf.\n",
    "\n",
    "`osf -p 9ahyp clone .`\n",
    "\n",
    "Otherwise you can download it using a Catalyst utility `download-gdrive` which downloads a version from the Catalyst Google Drive\n",
    "\n",
    "`usage: download-gdrive {FILE_ID} {FILENAME}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oupu01n3RJb5"
   },
   "outputs": [],
   "source": [
    "cd neuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VlogHK7RGkJ"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir Mindboggle_data \n",
    "mkdir -p data/Mindboggle_101/\n",
    "osf -p 9ahyp clone Mindboggle_data/\n",
    "cp -r Mindboggle_data/osfstorage/Mindboggle101_volumes/ data/Mindboggle_101/\n",
    "# manually unzip the files and remove the tar.gz files\n",
    "# find data/Mindboggle_101 -name '*.tar.gz'| xargs -i tar zxvf {} -C data/Mindboggle_101\n",
    "# find data/Mindboggle_101 -name '*.tar.gz'| xargs -i rm {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCJ4_qnGP_MA"
   },
   "source": [
    "Run the prepare data script that limits the labels to the DKT cortical labels (31 labels).  We can use of course use more labels.\n",
    "\n",
    "`usage: python ../neuro/scripts/prepare_data.py ../data/Mindboggle_101 {N_labels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/M295878/Projects/neuro\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "new_directory = \"/Users/M295878/Projects/neuro\"\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aBFRPKyuP_MA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "python neuro/scripts/prepare_data.py data/Mindboggle_101/ 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kviNcrfIP_MA"
   },
   "source": [
    "### **Create the relevant Dataloaders for the specified train, validation, and inference BrainDatasets.**\n",
    "\n",
    "BrainDatasets comprise of T1 scans + the prepared limited labels.\n",
    "\n",
    "Training/ Validation batches: To avoid sampling outside the brain area we randomly sampled NxNxN subvolumes from a gaussian distribution with the mean set in the center of the volume and the diagonal covariance set at 50.  This helps avoid class imbalance that would lead the model to simpley prefer the background class.\n",
    "\n",
    "Inference batches: All non-overlapping NxNxN Subvolumes across the existing volume space with their corresponding labels + randomly sampled NxNxN subvolumes from a the same gaussian distribution accross volume space as above until the required number of subvolume is reached.\n",
    "\n",
    "More detail can be found in brain_dataset.py and generator_coords.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IeFGpQ4_Ufdw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/M295878/Projects/neuro\n",
      "/Users/M295878/Projects/neuro/neuro\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "new_directory = \"/Users/M295878/Projects/neuro/neuro\"\n",
    "os.chdir(new_directory)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zjVQEnItP_MA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/M295878/Projects/neuro/neuro\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "import neuro\n",
    "from neuro.brain_dataset import BrainDataset\n",
    "from neuro.reader import NiftiFixedVolumeReader, NiftiReader\n",
    "from neuro.model import MeshNet, UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VSWPJkTgP_MA"
   },
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "  random_state: int,\n",
    "  volume_shape: List[int],\n",
    "  subvolume_shape: List[int],\n",
    "  in_csv_train: str = None,\n",
    "  in_csv_valid: str = None,\n",
    "  in_csv_infer: str = None,\n",
    "  batch_size: int = 32,\n",
    "  # TODO: maybe problematic as well\n",
    "  num_workers: int = 10,\n",
    ") -> dict:\n",
    "\n",
    "  datasets = {}\n",
    "  # global open_fn\n",
    "  open_fn = ReaderCompose(\n",
    "      [\n",
    "          NiftiFixedVolumeReader(input_key=\"images\", output_key=\"images\"),\n",
    "          NiftiReader(input_key=\"nii_labels\", output_key=\"targets\"),\n",
    "\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  for mode, source in zip((\"train\", \"validation\", \"infer\"),\n",
    "                          (in_csv_train, in_csv_valid, in_csv_infer)):\n",
    "      if mode == \"infer\":\n",
    "          n_subvolumes = 128#512\n",
    "      else:\n",
    "          n_subvolumes = 32#128\n",
    "\n",
    "      if source is not None and len(source) > 0:\n",
    "          dataset = BrainDataset(\n",
    "              list_data=dataframe_to_list(pd.read_csv(source)),\n",
    "              list_shape=volume_shape,\n",
    "              list_sub_shape=subvolume_shape,\n",
    "              open_fn=open_fn,\n",
    "              n_subvolumes=n_subvolumes,\n",
    "              mode=mode,\n",
    "              input_key=\"images\",\n",
    "              output_key=\"targets\",\n",
    "          )\n",
    "\n",
    "      datasets[mode] = {\"dataset\": dataset}\n",
    "      print(#dataset.data, \n",
    "            dataset.mode, \n",
    "            dataset.subjects,\n",
    "            dataset.n_subvolumes, \n",
    "            dataset.dict_transform,\n",
    "            dataset.open_fn,\n",
    "            dataset.input_key,\n",
    "            dataset.output_key,\n",
    "            dataset.subvolume_shape)\n",
    "  global worker_init_fn\n",
    "  def worker_init_fn(worker_id):\n",
    "      np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "\n",
    "  train_loader = DataLoader(dataset=datasets['train']['dataset'], \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True, \n",
    "                            worker_init_fn=worker_init_fn,\n",
    "                            num_workers=0, \n",
    "                            pin_memory=True)\n",
    "  valid_loader = DataLoader(dataset=datasets['validation']['dataset'],\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True, \n",
    "                            worker_init_fn=worker_init_fn,\n",
    "                            num_workers=0, \n",
    "                            pin_memory=True,\n",
    "                            drop_last=True)\n",
    "  test_loader = DataLoader(dataset=datasets['infer']['dataset'],\n",
    "                           batch_size=batch_size,\n",
    "                           worker_init_fn=worker_init_fn,\n",
    "                           num_workers=0, \n",
    "                           pin_memory=True,\n",
    "                           drop_last=True)\n",
    "  # debug\n",
    "  print(train_loader)\n",
    "  train_loaders = collections.OrderedDict()\n",
    "  infer_loaders = collections.OrderedDict()\n",
    "  train_loaders[\"train\"] = BatchPrefetchLoaderWrapper(train_loader)\n",
    "  train_loaders[\"valid\"] = BatchPrefetchLoaderWrapper(valid_loader)\n",
    "  infer_loaders['infer'] = BatchPrefetchLoaderWrapper(test_loader)\n",
    "\n",
    "  return train_loaders, infer_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XL43XWkYjCGx"
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir(\"/Users/M295878/Projects/neuro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ORmV32oeP_MA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 70 32 <function __id_fn__ at 0x295cd05e0> <catalyst.contrib.data.reader.ReaderCompose object at 0x295134670> images targets [38 38 38]\n",
      "validation 10 32 <function __id_fn__ at 0x295cd05e0> <catalyst.contrib.data.reader.ReaderCompose object at 0x295134670> images targets [38 38 38]\n",
      "infer 21 128 <function __id_fn__ at 0x295cd05e0> <catalyst.contrib.data.reader.ReaderCompose object at 0x295134670> images targets [38 38 38]\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x295136080>\n"
     ]
    }
   ],
   "source": [
    "volume_shape = [256, 256, 256]\n",
    "subvolume_shape = [38, 38, 38]\n",
    "train_loaders, infer_loaders = get_loaders(\n",
    "    123, volume_shape, subvolume_shape,\n",
    "    \"./data/dataset_train.csv\",\n",
    "    \"./data/dataset_valid.csv\",\n",
    "    \"./data/dataset_infer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loadersOrderedDict([('train', <catalyst.data.loader.BatchPrefetchLoaderWrapper object at 0x2939a77f0>), ('valid', <catalyst.data.loader.BatchPrefetchLoaderWrapper object at 0x2939a6cb0>)])\n",
      "infer_loadersOrderedDict([('infer', <catalyst.data.loader.BatchPrefetchLoaderWrapper object at 0x29500ce50>)])\n"
     ]
    }
   ],
   "source": [
    "print(f'train_loaders{train_loaders}')\n",
    "print(f'infer_loaders{infer_loaders}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_Qav0lxP_MA"
   },
   "source": [
    "# Model Training\n",
    "\n",
    "We'll train the model 30 epochs.\n",
    "\n",
    "* Scheduler: Adam with a One Cycle Learning Rate with a Max Learning Rate of .02\n",
    "* Batch Metric: DICE\n",
    "* Loss: CrossEntropyLoss\n",
    "* Logger: Tensorboard\n",
    "* CheckpointerCallback\n",
    "\n",
    "For training and validation we sample the volume with subvolumes specified in our Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TFnFWvyZXt5l"
   },
   "outputs": [],
   "source": [
    "class CustomRunner(Runner):\n",
    "\n",
    "    def get_loaders(self, stage: str) -> \"OrderedDict[str, DataLoader]\":\n",
    "        \"\"\"Returns the loaders for a given stage.\"\"\"\n",
    "        self._loaders = self._loaders\n",
    "        return self._loaders\n",
    "\n",
    "    def predict_batch(self, batch):\n",
    "        # model inference step\n",
    "        batch = batch[0]\n",
    "        return self.model(batch['images'].float().to(self.device)), batch['coords']\n",
    "\n",
    "    def on_loader_start(self, runner):\n",
    "        super().on_loader_start(runner)\n",
    "        self.meters = {\n",
    "          key: metrics.AdditiveValueMetric(compute_on_call=False)\n",
    "          for key in [\"loss\", \"macro_dice\"]\n",
    "        }\n",
    "\n",
    "    def handle_batch(self, batch):\n",
    "        # model train/valid step\n",
    "        batch = batch[0]\n",
    "        x, y = batch['images'].float(), batch['targets']\n",
    "\n",
    "        if self.is_train_loader:\n",
    "          self.optimizer.zero_grad()\n",
    "\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        if self.is_train_loader:\n",
    "          loss.backward()\n",
    "          self.optimizer.step()\n",
    "          scheduler.step()\n",
    "\n",
    "        one_hot_targets = (\n",
    "          torch.nn.functional.one_hot(y, 31)\n",
    "          .permute(0, 4, 1, 2, 3)\n",
    "          #.cuda()\n",
    "        )\n",
    "\n",
    "        logits_softmax = F.softmax(y_hat)\n",
    "        macro_dice = dice(logits_softmax, one_hot_targets, mode='macro')\n",
    "\n",
    "        self.batch_metrics.update({\"loss\": loss, 'macro_dice': macro_dice})\n",
    "        for key in [\"loss\", \"macro_dice\"]:\n",
    "          self.meters[key].update(self.batch_metrics[key].item(), self.batch_size)\n",
    "\n",
    "    def on_loader_end(self, runner):\n",
    "        for key in [\"loss\", \"macro_dice\"]:\n",
    "            self.loader_metrics[key] = self.meters[key].compute()[0]\n",
    "        super().on_loader_end(runner)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "id": "XQ9dzP86dAmx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-device branch, line 678\n",
      "running epoch0, line 657\n",
      "_run_epoch step, line 642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db55090946c043a1af363ddb6c534fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/2 * Epoch (train):   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loader, line 629\n",
      "in loader loop, line 633\n",
      "current loader<enumerate object at 0x295c7ecc0>, line 634\n",
      "running batch0, line 632\n",
      "_run_batch step line 620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/0v8_z4bs7z37v8j35_1pxjj40000gs/T/ipykernel_69833/3561788891.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logits_softmax = F.softmax(y_hat)\n",
      "/Users/M295878/anaconda3/lib/python3.10/site-packages/catalyst/core/runner.py:566: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k: runner.engine.sync_tensor(torch.tensor(v, device=runner.device), \"mean\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running batch1, line 632\n",
      "_run_batch step line 620\n",
      "running batch2, line 632\n",
      "_run_batch step line 620\n",
      "running batch3, line 632\n",
      "_run_batch step line 620\n",
      "running batch4, line 632\n",
      "_run_batch step line 620\n",
      "running batch5, line 632\n",
      "_run_batch step line 620\n",
      "running batch6, line 632\n",
      "_run_batch step line 620\n",
      "running batch7, line 632\n",
      "_run_batch step line 620\n",
      "running batch8, line 632\n",
      "_run_batch step line 620\n",
      "running batch9, line 632\n",
      "_run_batch step line 620\n",
      "running batch10, line 632\n",
      "_run_batch step line 620\n",
      "running batch11, line 632\n",
      "_run_batch step line 620\n",
      "running batch12, line 632\n",
      "_run_batch step line 620\n",
      "running batch13, line 632\n",
      "_run_batch step line 620\n",
      "running batch14, line 632\n",
      "_run_batch step line 620\n",
      "running batch15, line 632\n",
      "_run_batch step line 620\n",
      "running batch16, line 632\n",
      "_run_batch step line 620\n",
      "running batch17, line 632\n",
      "_run_batch step line 620\n",
      "running batch18, line 632\n",
      "_run_batch step line 620\n",
      "running batch19, line 632\n",
      "_run_batch step line 620\n",
      "running batch20, line 632\n",
      "_run_batch step line 620\n",
      "running batch21, line 632\n",
      "_run_batch step line 620\n",
      "running batch22, line 632\n",
      "_run_batch step line 620\n",
      "running batch23, line 632\n",
      "_run_batch step line 620\n",
      "running batch24, line 632\n",
      "_run_batch step line 620\n",
      "running batch25, line 632\n",
      "_run_batch step line 620\n",
      "running batch26, line 632\n",
      "_run_batch step line 620\n",
      "running batch27, line 632\n",
      "_run_batch step line 620\n",
      "running batch28, line 632\n",
      "_run_batch step line 620\n",
      "running batch29, line 632\n",
      "_run_batch step line 620\n",
      "running batch30, line 632\n",
      "_run_batch step line 620\n",
      "running batch31, line 632\n",
      "_run_batch step line 620\n",
      "running batch32, line 632\n",
      "_run_batch step line 620\n",
      "running batch33, line 632\n",
      "_run_batch step line 620\n",
      "running batch34, line 632\n",
      "_run_batch step line 620\n",
      "running batch35, line 632\n",
      "_run_batch step line 620\n",
      "running batch36, line 632\n",
      "_run_batch step line 620\n",
      "running batch37, line 632\n",
      "_run_batch step line 620\n",
      "running batch38, line 632\n",
      "_run_batch step line 620\n",
      "running batch39, line 632\n",
      "_run_batch step line 620\n",
      "running batch40, line 632\n",
      "_run_batch step line 620\n",
      "running batch41, line 632\n",
      "_run_batch step line 620\n",
      "running batch42, line 632\n",
      "_run_batch step line 620\n",
      "running batch43, line 632\n",
      "_run_batch step line 620\n",
      "running batch44, line 632\n",
      "_run_batch step line 620\n",
      "running batch45, line 632\n",
      "_run_batch step line 620\n",
      "running batch46, line 632\n",
      "_run_batch step line 620\n",
      "running batch47, line 632\n",
      "_run_batch step line 620\n",
      "running batch48, line 632\n",
      "_run_batch step line 620\n",
      "running batch49, line 632\n",
      "_run_batch step line 620\n",
      "running batch50, line 632\n",
      "_run_batch step line 620\n",
      "running batch51, line 632\n",
      "_run_batch step line 620\n",
      "running batch52, line 632\n",
      "_run_batch step line 620\n",
      "running batch53, line 632\n",
      "_run_batch step line 620\n",
      "running batch54, line 632\n",
      "_run_batch step line 620\n",
      "running batch55, line 632\n",
      "_run_batch step line 620\n",
      "running batch56, line 632\n",
      "_run_batch step line 620\n",
      "running batch57, line 632\n",
      "_run_batch step line 620\n",
      "running batch58, line 632\n",
      "_run_batch step line 620\n",
      "running batch59, line 632\n",
      "_run_batch step line 620\n",
      "running batch60, line 632\n",
      "_run_batch step line 620\n",
      "running batch61, line 632\n",
      "_run_batch step line 620\n",
      "running batch62, line 632\n",
      "_run_batch step line 620\n",
      "running batch63, line 632\n",
      "_run_batch step line 620\n",
      "running batch64, line 632\n",
      "_run_batch step line 620\n",
      "running batch65, line 632\n",
      "_run_batch step line 620\n",
      "running batch66, line 632\n",
      "_run_batch step line 620\n",
      "running batch67, line 632\n",
      "_run_batch step line 620\n",
      "running batch68, line 632\n",
      "_run_batch step line 620\n",
      "running batch69, line 632\n",
      "_run_batch step line 620\n",
      "train (1/2) loss: 0.6623132105384553 | macro_dice: 0.02882905819985483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd67c50a2e640bfae8133b5b7e624fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/2 * Epoch (valid):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loader, line 629\n",
      "in loader loop, line 633\n",
      "current loader<enumerate object at 0x295cbb640>, line 634\n",
      "running batch0, line 632\n",
      "_run_batch step line 620\n",
      "running batch1, line 632\n",
      "_run_batch step line 620\n",
      "running batch2, line 632\n",
      "_run_batch step line 620\n",
      "running batch3, line 632\n",
      "_run_batch step line 620\n",
      "running batch4, line 632\n",
      "_run_batch step line 620\n",
      "running batch5, line 632\n",
      "_run_batch step line 620\n",
      "running batch6, line 632\n",
      "_run_batch step line 620\n",
      "running batch7, line 632\n",
      "_run_batch step line 620\n",
      "running batch8, line 632\n",
      "_run_batch step line 620\n",
      "running batch9, line 632\n",
      "_run_batch step line 620\n",
      "valid (1/2) loss: 0.2442310579121113 | macro_dice: 0.03293756246566772\n",
      "* Epoch (1/2) \n",
      "running epoch1, line 657\n",
      "_run_epoch step, line 642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e109bb74044a6c83ce30cc13acca6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/2 * Epoch (train):   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loader, line 629\n",
      "in loader loop, line 633\n",
      "current loader<enumerate object at 0x294b12d00>, line 634\n",
      "running batch0, line 632\n",
      "_run_batch step line 620\n",
      "running batch1, line 632\n",
      "_run_batch step line 620\n",
      "running batch2, line 632\n",
      "_run_batch step line 620\n",
      "running batch3, line 632\n",
      "_run_batch step line 620\n",
      "running batch4, line 632\n",
      "_run_batch step line 620\n",
      "running batch5, line 632\n",
      "_run_batch step line 620\n",
      "running batch6, line 632\n",
      "_run_batch step line 620\n",
      "running batch7, line 632\n",
      "_run_batch step line 620\n",
      "running batch8, line 632\n",
      "_run_batch step line 620\n",
      "running batch9, line 632\n",
      "_run_batch step line 620\n",
      "running batch10, line 632\n",
      "_run_batch step line 620\n",
      "running batch11, line 632\n",
      "_run_batch step line 620\n",
      "running batch12, line 632\n",
      "_run_batch step line 620\n",
      "running batch13, line 632\n",
      "_run_batch step line 620\n",
      "running batch14, line 632\n",
      "_run_batch step line 620\n",
      "running batch15, line 632\n",
      "_run_batch step line 620\n",
      "running batch16, line 632\n",
      "_run_batch step line 620\n",
      "running batch17, line 632\n",
      "_run_batch step line 620\n",
      "running batch18, line 632\n",
      "_run_batch step line 620\n",
      "running batch19, line 632\n",
      "_run_batch step line 620\n",
      "running batch20, line 632\n",
      "_run_batch step line 620\n",
      "running batch21, line 632\n",
      "_run_batch step line 620\n",
      "running batch22, line 632\n",
      "_run_batch step line 620\n",
      "running batch23, line 632\n",
      "_run_batch step line 620\n",
      "running batch24, line 632\n",
      "_run_batch step line 620\n",
      "running batch25, line 632\n",
      "_run_batch step line 620\n",
      "running batch26, line 632\n",
      "_run_batch step line 620\n",
      "running batch27, line 632\n",
      "_run_batch step line 620\n",
      "running batch28, line 632\n",
      "_run_batch step line 620\n",
      "running batch29, line 632\n",
      "_run_batch step line 620\n",
      "running batch30, line 632\n",
      "_run_batch step line 620\n",
      "running batch31, line 632\n",
      "_run_batch step line 620\n",
      "running batch32, line 632\n",
      "_run_batch step line 620\n",
      "running batch33, line 632\n",
      "_run_batch step line 620\n",
      "running batch34, line 632\n",
      "_run_batch step line 620\n",
      "running batch35, line 632\n",
      "_run_batch step line 620\n",
      "running batch36, line 632\n",
      "_run_batch step line 620\n",
      "running batch37, line 632\n",
      "_run_batch step line 620\n",
      "running batch38, line 632\n",
      "_run_batch step line 620\n",
      "running batch39, line 632\n",
      "_run_batch step line 620\n",
      "running batch40, line 632\n",
      "_run_batch step line 620\n",
      "running batch41, line 632\n",
      "_run_batch step line 620\n",
      "running batch42, line 632\n",
      "_run_batch step line 620\n",
      "running batch43, line 632\n",
      "_run_batch step line 620\n",
      "running batch44, line 632\n",
      "_run_batch step line 620\n",
      "running batch45, line 632\n",
      "_run_batch step line 620\n",
      "running batch46, line 632\n",
      "_run_batch step line 620\n",
      "running batch47, line 632\n",
      "_run_batch step line 620\n",
      "running batch48, line 632\n",
      "_run_batch step line 620\n",
      "running batch49, line 632\n",
      "_run_batch step line 620\n",
      "running batch50, line 632\n",
      "_run_batch step line 620\n",
      "running batch51, line 632\n",
      "_run_batch step line 620\n",
      "running batch52, line 632\n",
      "_run_batch step line 620\n",
      "running batch53, line 632\n",
      "_run_batch step line 620\n",
      "running batch54, line 632\n",
      "_run_batch step line 620\n",
      "running batch55, line 632\n",
      "_run_batch step line 620\n",
      "running batch56, line 632\n",
      "_run_batch step line 620\n",
      "running batch57, line 632\n",
      "_run_batch step line 620\n",
      "running batch58, line 632\n",
      "_run_batch step line 620\n",
      "running batch59, line 632\n",
      "_run_batch step line 620\n",
      "running batch60, line 632\n",
      "_run_batch step line 620\n",
      "running batch61, line 632\n",
      "_run_batch step line 620\n",
      "running batch62, line 632\n",
      "_run_batch step line 620\n",
      "running batch63, line 632\n",
      "_run_batch step line 620\n",
      "running batch64, line 632\n",
      "_run_batch step line 620\n",
      "running batch65, line 632\n",
      "_run_batch step line 620\n",
      "running batch66, line 632\n",
      "_run_batch step line 620\n",
      "running batch67, line 632\n",
      "_run_batch step line 620\n",
      "running batch68, line 632\n",
      "_run_batch step line 620\n",
      "running batch69, line 632\n",
      "_run_batch step line 620\n",
      "train (2/2) loss: 0.27340402911816325 | macro_dice: 0.033794636917965734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e52d5bcc0649e19bd053e0ea9d1011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/2 * Epoch (valid):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loader, line 629\n",
      "in loader loop, line 633\n",
      "current loader<enumerate object at 0x2952e85c0>, line 634\n",
      "running batch0, line 632\n",
      "_run_batch step line 620\n",
      "running batch1, line 632\n",
      "_run_batch step line 620\n",
      "running batch2, line 632\n",
      "_run_batch step line 620\n",
      "running batch3, line 632\n",
      "_run_batch step line 620\n",
      "running batch4, line 632\n",
      "_run_batch step line 620\n",
      "running batch5, line 632\n",
      "_run_batch step line 620\n",
      "running batch6, line 632\n",
      "_run_batch step line 620\n",
      "running batch7, line 632\n",
      "_run_batch step line 620\n",
      "running batch8, line 632\n",
      "_run_batch step line 620\n",
      "running batch9, line 632\n",
      "_run_batch step line 620\n",
      "valid (2/2) loss: 0.23629454299807548 | macro_dice: 0.03377584107220173\n",
      "* Epoch (2/2) \n",
      "Top best models:\n",
      "logs/meshnet_mindboggle/train.2.pth\t2.0000\n"
     ]
    }
   ],
   "source": [
    "n_classes = 31\n",
    "n_epochs = 2\n",
    "meshnet = MeshNet(n_channels=1, n_classes=n_classes)\n",
    "unet = UNet(n_channels=1, n_classes=n_classes)\n",
    "\n",
    "logdir = \"logs/meshnet_mindboggle\"\n",
    "\n",
    "optimizer = torch.optim.Adam(meshnet.parameters(), lr=0.02)\n",
    "\n",
    "\n",
    "scheduler = OneCycleLR(optimizer, max_lr=.02,\n",
    "                 epochs=n_epochs, steps_per_epoch=len(train_loaders['train']))\n",
    "\n",
    "runner = CustomRunner()\n",
    "runner.train(\n",
    "    model=meshnet,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=train_loaders,\n",
    "    num_epochs=n_epochs,\n",
    "    logdir=logdir,\n",
    "    callbacks=[CheckpointCallback(logdir=logdir)],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqJgyfgIsLZ4"
   },
   "source": [
    "# Model Evaluation\n",
    "\n",
    "For every brain volume we implement a majority vote for every voxel and use  that to compute a Dice score.\n",
    "\n",
    "\n",
    "The initial volume is segmented into\n",
    "a regular grid of subvolumes partitioning the whole volume.\n",
    "These volumes ensure a prediction for each voxel. Then we\n",
    "sample overlapping volumes from the brain region until N\n",
    "subvolumes (512 in this case) are achieved for prediction.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sijB1BVYisp4"
   },
   "outputs": [],
   "source": [
    "def voxel_majority_predict_from_subvolumes(loader, n_classes, segmentations):\n",
    "    if segmentations is None:\n",
    "        for subject in range(loader.dataset.subjects):\n",
    "            segmentations[subject] = torch.zeros(\n",
    "                tuple(np.insert(loader.volume_shape, 0, n_classes)),\n",
    "                dtype=torch.uint8).cpu()\n",
    "\n",
    "    prediction_n = 0\n",
    "    for inference in tqdm(runner.predict_loader(loader=loader)):\n",
    "        coords = inference[1].cpu()\n",
    "        _, predicted = torch.max(F.log_softmax(inference[0].cpu(), dim=1), 1)\n",
    "        for j in range(predicted.shape[0]):\n",
    "            c_j = coords[j][0]\n",
    "            subj_id = prediction_n // loader.dataset.n_subvolumes\n",
    "            for c in range(n_classes):\n",
    "                segmentations[subj_id][c, c_j[0, 0]:c_j[0, 1],\n",
    "                                       c_j[1, 0]:c_j[1, 1],\n",
    "                                       c_j[2, 0]:c_j[2, 1]] += (predicted[j] == c)\n",
    "            prediction_n += 1\n",
    "\n",
    "    for i in segmentations.keys():\n",
    "        segmentations[i] = torch.max(segmentations[i], 0)[1]\n",
    "    return segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "al25kqCRV4En"
   },
   "outputs": [],
   "source": [
    "segmentations = {}\n",
    "for subject in range(infer_loaders['infer'].dataset.subjects):\n",
    "    segmentations[subject] = torch.zeros(tuple(np.insert(volume_shape, 0, n_classes)), dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0TdoZPOGVbaQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [1:43:13, 73.73s/it]\n",
      "100%|██████████| 21/21 [05:27<00:00, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1    2    3    4    5    6    7    8    9   ...   21   22   23  \\\n",
      "0   0.993066  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1   0.992974  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2   0.992922  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3   0.994251  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4   0.994192  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "5   0.991677  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6   0.992616  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "7   0.993213  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "8   0.992958  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "9   0.994629  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "10  0.992799  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "11  0.992821  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "12  0.991686  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "13  0.992206  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "14  0.992350  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "15  0.993103  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "16  0.994289  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "17  0.992519  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "18  0.993066  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "19  0.992988  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "20  0.992159  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "     24   25   26   27   28   29   30  \n",
      "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "19  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[21 rows x 31 columns]            0\n",
      "0   0.032034\n",
      "1   0.032031\n",
      "2   0.032030\n",
      "3   0.032073\n",
      "4   0.032071\n",
      "5   0.031990\n",
      "6   0.032020\n",
      "7   0.032039\n",
      "8   0.032031\n",
      "9   0.032085\n",
      "10  0.032026\n",
      "11  0.032026\n",
      "12  0.031990\n",
      "13  0.032007\n",
      "14  0.032011\n",
      "15  0.032036\n",
      "16  0.032074\n",
      "17  0.032017\n",
      "18  0.032034\n",
      "19  0.032032\n",
      "20  0.032005\n",
      "0    0.032031\n",
      "dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "segmentations = voxel_majority_predict_from_subvolumes(infer_loaders['infer'],\n",
    "                                                     n_classes, segmentations)\n",
    "subject_metrics = []\n",
    "for subject, subject_data in enumerate(tqdm(infer_loaders['infer'].dataset.data)):\n",
    "    seg_labels = nib.load(subject_data['nii_labels']).get_fdata()\n",
    "    segmentation_labels = torch.nn.functional.one_hot(\n",
    "        torch.from_numpy(seg_labels).to(torch.int64), n_classes)\n",
    "\n",
    "    inference_dice = dice(\n",
    "        torch.nn.functional.one_hot(segmentations[subject], n_classes).permute(0, 3, 1, 2),\n",
    "        segmentation_labels.permute(0, 3, 1, 2)\n",
    "    ).detach().numpy()\n",
    "    macro_inference_dice = dice(\n",
    "        torch.nn.functional.one_hot(segmentations[subject], n_classes).permute(0, 3, 1, 2),\n",
    "        segmentation_labels.permute(0, 3, 1, 2), mode='macro'\n",
    "    ).detach().numpy()\n",
    "    subject_metrics.append((inference_dice, macro_inference_dice))\n",
    "\n",
    "per_class_df = pd.DataFrame([metric[0] for metric in subject_metrics])\n",
    "macro_df = pd.DataFrame([metric[1] for metric in subject_metrics])\n",
    "print(per_class_df, macro_df)\n",
    "print(macro_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Neuro UNet Demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
